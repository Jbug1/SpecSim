{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages internal and external\n",
    "import tests\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import datasetBuilder\n",
    "import tools\n",
    "import scipy\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "import sklearn.base\n",
    "import pickle\n",
    "import copy\n",
    "import tests\n",
    "from sklearn.metrics import roc_auc_score as auc\n",
    "import os\n",
    "import plotAndOrderResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path variables where we want to save created datasets, intermediate outputs, etc\n",
    "#If you want to run this on your own computer, obviously you should update the path\n",
    "outputs_path='/Users/jonahpoczobutt/projects/specsim_res/figOutputs'\n",
    "\n",
    "\n",
    "nist14='/Users/jonahpoczobutt/projects/raw_data/db_csvs/nist14.pkl'\n",
    "gnps='/Users/jonahpoczobutt/projects/raw_data/db_csvs/gnps.pkl'\n",
    "mona='/Users/jonahpoczobutt/projects/raw_data/db_csvs/mona_lc.pkl'\n",
    "metlin='/Users/jonahpoczobutt/projects/raw_data/db_csvs/metlin_experimental.pkl'\n",
    "\n",
    "#Set the query and target dbs\n",
    "#these can be different or the same\n",
    "query = metlin\n",
    "target = nist14\n",
    "\n",
    "#This variable toggles whether we do a full run of the notebook, or if we read in variables created in a previous run\n",
    "fullRun=True\n",
    "\n",
    "#create directories for results\n",
    "if fullRun:\n",
    "    \n",
    "    os.mkdir(f'{outputs_path}/intermediateOutputs')\n",
    "    os.mkdir(f'{outputs_path}/fig1')\n",
    "    os.mkdir(f'{outputs_path}/fig1/fig1a')\n",
    "    os.mkdir(f'{outputs_path}/fig1/supplementary')\n",
    "    os.mkdir(f'{outputs_path}/fig1/fig1b')\n",
    "    os.mkdir(f'{outputs_path}/fig2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing: Creating Target and Matches DFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fullRun:\n",
    "\n",
    "    #This should be replaced with a function to read in all the databases\n",
    "    query_ = pd.read_pickle(query)\n",
    "    all_bases = list(set(query_['inchi_base']))\n",
    "\n",
    "    first_bases = all_bases[:int(len(all_bases)/2)]\n",
    "    second_bases = all_bases[int(len(all_bases)/2):]\n",
    "\n",
    "    first_query_ = query_[np.isin(query_['inchi_base'],first_bases)]\n",
    "    first_query_.reset_index(inplace=True)\n",
    "    first_query_.to_csv(f'{outputs_path}/intermediateOutputs/first_query.csv')\n",
    "    del(first_query_)\n",
    "\n",
    "    second_query_ = query_[np.isin(query_['inchi_base'],first_bases)]\n",
    "    second_query_.reset_index(inplace=True)\n",
    "    second_query_.to_csv(f'{outputs_path}/intermediateOutputs/second_query.csv')\n",
    "    del(second_query_)\n",
    "    del(query_)\n",
    "\n",
    "    \n",
    "    np.save(f'{outputs_path}/intermediateOutputs/first_bases.npy',first_bases)\n",
    "    np.save(f'{outputs_path}/intermediateOutputs/second_bases.npy',second_bases)\n",
    "    del(first_bases)\n",
    "    del(second_bases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1a: Global Performance of Individual Metrics/Weighting Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'isv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'isv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonahpoczobutt/projects/SpecSim/figures.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/figures.ipynb#X15sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m target_\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_pickle(target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/figures.ipynb#X15sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ppm_windows:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/figures.ipynb#X15sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     matches \u001b[39m=\u001b[39m datasetBuilder\u001b[39m.\u001b[39mcreate_matches_df_new(query_,target_,i,max_matches,size)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/figures.ipynb#X15sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     matches\u001b[39m.\u001b[39mto_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00moutputs_path\u001b[39m}\u001b[39;00m\u001b[39m/fig1/supplementary/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m_ppm.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/figures.ipynb#X15sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m#comparison on large sample\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/SpecSim/datasetBuilder.py:1278\u001b[0m, in \u001b[0;36mcreate_matches_df_new\u001b[0;34m(query_df, target_df, precursor_thresh, max_rows_per_query, max_len)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     printy \u001b[39m=\u001b[39m printy \u001b[39m+\u001b[39m \u001b[39m1e5\u001b[39m\n\u001b[1;32m   1277\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1278\u001b[0m     out \u001b[39m=\u001b[39m within_range\u001b[39m.\u001b[39mapply(\n\u001b[1;32m   1279\u001b[0m         \u001b[39mlambda\u001b[39;00m x: add_non_spec_features(target_df\u001b[39m.\u001b[39miloc[i], x),\n\u001b[1;32m   1280\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1281\u001b[0m         result_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpand\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[1;32m   1283\u001b[0m     out\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m non_spec_columns\n\u001b[1;32m   1285\u001b[0m     out[\u001b[39m\"\u001b[39m\u001b[39mquery_prec\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m query_df\u001b[39m.\u001b[39miloc[i][\u001b[39m\"\u001b[39m\u001b[39mprecursor\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_series_generator()\n\u001b[1;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(v)\n\u001b[1;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects/SpecSim/datasetBuilder.py:1279\u001b[0m, in \u001b[0;36mcreate_matches_df_new.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1275\u001b[0m     printy \u001b[39m=\u001b[39m printy \u001b[39m+\u001b[39m \u001b[39m1e5\u001b[39m\n\u001b[1;32m   1277\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m     out \u001b[39m=\u001b[39m within_range\u001b[39m.\u001b[39mapply(\n\u001b[0;32m-> 1279\u001b[0m         \u001b[39mlambda\u001b[39;00m x: add_non_spec_features(target_df\u001b[39m.\u001b[39miloc[i], x),\n\u001b[1;32m   1280\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1281\u001b[0m         result_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpand\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[1;32m   1283\u001b[0m     out\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m non_spec_columns\n\u001b[1;32m   1285\u001b[0m     out[\u001b[39m\"\u001b[39m\u001b[39mquery_prec\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m query_df\u001b[39m.\u001b[39miloc[i][\u001b[39m\"\u001b[39m\u001b[39mprecursor\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/projects/SpecSim/datasetBuilder.py:1008\u001b[0m, in \u001b[0;36madd_non_spec_features\u001b[0;34m(query_row, target_row)\u001b[0m\n\u001b[1;32m   1005\u001b[0m outrow \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m14\u001b[39m)\n\u001b[1;32m   1007\u001b[0m \u001b[39m# individual features\u001b[39;00m\n\u001b[0;32m-> 1008\u001b[0m outrow[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(query_row[\u001b[39m\"\u001b[39m\u001b[39misv\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   1009\u001b[0m outrow[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(query_row[\u001b[39m\"\u001b[39m\u001b[39mcollision_energy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   1010\u001b[0m outrow[\u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(target_row[\u001b[39m\"\u001b[39m\u001b[39misv\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'isv'"
     ]
    }
   ],
   "source": [
    "#these are the ppm windows that we want to test\n",
    "ppm_windows = [10]\n",
    "\n",
    "#this is the size of the sample we take from the full target\n",
    "size=1e3\n",
    "\n",
    "#this is the maximum number of matches we allow for each query, based on the precursor window\n",
    "max_matches=100\n",
    "\n",
    "#Similarity methods and transformation parameters below. Leave sim methods as None to run all\n",
    "noise_threshes=[0.01,0.05,0.1]\n",
    "centroid_tolerance_vals = [0.05,3]\n",
    "centroid_tolerance_types=['da','ppm']\n",
    "powers=[0.25,1,3,'ent',None]\n",
    "ppm_threshes = [3,5,10,15]\n",
    "sim_methods=None\n",
    "\n",
    "if fullRun:\n",
    "    #we will evaluate the performace of the individual metrics on a large sample from the\n",
    "    #full target dataset. You can set the size below\n",
    "\n",
    "    #reload queries and target for individual comparison\n",
    "    query_=pd.read_pickle(query)\n",
    "    target_=pd.read_pickle(target)\n",
    "\n",
    "    for i in ppm_windows:\n",
    "\n",
    "        matches = datasetBuilder.create_matches_df_new(query_,target_,i,max_matches,size)\n",
    "        matches.to_csv(f'{outputs_path}/fig1/supplementary/{i}_ppm.csv')\n",
    "\n",
    "        #comparison on large sample\n",
    "        tests.create_variable_comparisons(\n",
    "                                noise_threshes=noise_threshes,\n",
    "                                centroid_threshes=centroid_tolerance_vals,\n",
    "                                centroid_types=centroid_tolerance_types,\n",
    "                                powers=powers,\n",
    "                                sim_methods=sim_methods,\n",
    "                                matches=matches,\n",
    "                                outfolder = f'{outputs_path}/fig1/fig1a'\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1b: Assessing Metric Stability in Smaller Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the size of the sample we take from the full target\n",
    "size=1e4\n",
    "\n",
    "#this is the number of times we want to take a sample of the above size\n",
    "trials=100\n",
    "\n",
    "if fullRun:\n",
    "    #we will evaluate the performace of the individual metrics on a large sample from the\n",
    "    #full target dataset. You can set the size below\n",
    "\n",
    "    #reload target\n",
    "    query=pd.read_picle(query)\n",
    "    target=pd.read_pickle(target)\n",
    "\n",
    "    for i in ppm_threshes:\n",
    "        \n",
    "        matches = datasetBuilder.create_matches_df_new(query,target,i,max_matches,size)\n",
    "        \n",
    "        for j in range(trials):\n",
    "\n",
    "            os.mkdir(f'{outputs_path}/fig1/fig1b/{j}')\n",
    "\n",
    "            #comparison on small sample\n",
    "            tests.create_variable_comparisons(query, target,\n",
    "                                    size=size,\n",
    "                                    noise_threshes=noise_threshes,\n",
    "                                    centroid_threshes=centroid_tolerance_vals,\n",
    "                                    centroid_types=centroid_tolerance_types,\n",
    "                                    powers=powers,\n",
    "                                    sim_methods=sim_methods,\n",
    "                                    matches=matches\n",
    "                                    outfolder = f'{outputs_path}/fig1/fig1b/{j}'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figures 1a and 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, generate tables from full size\n",
    "metrics, xs, ys = plotAndOrderResults.fig1a(f'{outputs_path}/fig1/fig1a')\n",
    "\n",
    "for i in range(len(metrics)):\n",
    "    plt.plot(xs[i], ys[i], label=metrics[i])\n",
    "\n",
    "plt.xlabel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure 1\n",
    "#column 3 is noise clip, peak consolidation value and type, weighting\n",
    "#none weighting is the original weighted entropy scheme from the paper\n",
    "ppm3 = pd.read_csv('/Users/jonahpoczobutt/projects/specsim_res/individual_sims/matches_3_ppm.csv', header=None)\n",
    "ppm3.sort_values(by=2, ascending=False, inplace=True)\n",
    "\n",
    "ppm5 = pd.read_csv('/Users/jonahpoczobutt/projects/specsim_res/individual_sims/matches_5_ppm.csv', header=None)\n",
    "ppm5.sort_values(by=2, ascending=False, inplace=True)\n",
    "\n",
    "ppm10 = pd.read_csv('/Users/jonahpoczobutt/projects/specsim_res/individual_sims/matches_10_ppm.csv', header=None)\n",
    "ppm10.sort_values(by=2, ascending=False, inplace=True)\n",
    "\n",
    "ppm15 = pd.read_csv('/Users/jonahpoczobutt/projects/specsim_res/individual_sims/matches_15_ppm.csv', header=None)\n",
    "ppm15.sort_values(by=2, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
