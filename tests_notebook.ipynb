{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65d6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T03:45:16.757600Z",
     "start_time": "2023-08-13T03:45:14.306478Z"
    }
   },
   "outputs": [],
   "source": [
    "#import datasetBuilder\n",
    "import tests\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import datasetBuilder\n",
    "import tools\n",
    "import scipy\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "import sklearn.base\n",
    "import pickle\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda901b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_bases = np.load('C:\\\\Users\\\\jonah\\\\projects\\\\specsim_res\\\\first_bases.npy')\n",
    "second_bases = np.load('C:\\\\Users\\\\jonah\\\\projects\\\\specsim_res\\\\second_bases.npy')\n",
    "#first_target = target[np.isin(target['inchi_base'],first_bases)]\n",
    "#second_target = target[np.isin(target['inchi_base'],second_bases)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(datasetBuilder)\n",
    "reload(tools)\n",
    "noise_threshes=[0.01,0.1,0.2]\n",
    "centroid_tolerance_vals = [0.05,1]\n",
    "centroid_tolerance_types=['da','ppm']\n",
    "powers=[0.25,1,3,'ent']\n",
    "sim_methods = ['lorentzian','max_entropy','squared_chord','lorentzian_jonah','rbf','ave_bhattacharya_2','max_bhattacharya_2']\n",
    "\n",
    "matches = datasetBuilder.create_matches_df(first_target,10,100,1e6)\n",
    "og_matches = matches.copy()\n",
    "datasetBuilder.add_noises_to_matches(matches, scale_ratio=0.5, mult=200)\n",
    "\n",
    "print(f'match len predrop {len(matches)}')\n",
    "matches=matches.dropna(how='any')\n",
    "print(f'match len postdrop {len(matches)}')\n",
    "\n",
    "cleaned, mod = datasetBuilder.create_model_dataset(matches, sim_methods = sim_methods, noise_threshes=noise_threshes, centroid_tolerance_vals=centroid_tolerance_vals, centroid_tolerance_types=centroid_tolerance_types,powers=powers)\n",
    "mod.to_csv('C:\\\\Users\\\\jonah\\\\projects\\\\specsim_res\\\\noise_first_0.5_200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6884435",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(matches)\n",
    "del(mod)\n",
    "del (first_target)\n",
    "second_target = target[np.isin(target['inchi_base'],second_bases)]\n",
    "\n",
    "noise_threshes=[0.01,0.1,0.2]\n",
    "centroid_tolerance_vals = [0.05,1]\n",
    "centroid_tolerance_types=['da','ppm']\n",
    "powers=[0.25,1,3,'ent']\n",
    "sim_methods = ['lorentzian','max_entropy','squared_chord','lorentzian_jonah','rbf','ave_bhattacharya_2','max_bhattacharya_2']\n",
    "\n",
    "matches = datasetBuilder.create_matches_df(second_target,10,100,1e6)\n",
    "datasetBuilder.add_noises_to_matches(matches, scale_ratio=0.5, mult=200)\n",
    "print(f'match len predrop {len(matches)}')\n",
    "matches=matches.dropna(how='any')\n",
    "print(f'match len postdrop {len(matches)}')\n",
    "\n",
    "mod = datasetBuilder.create_model_dataset(matches, sim_methods = sim_methods, noise_threshes=noise_threshes, centroid_tolerance_vals=centroid_tolerance_vals, centroid_tolerance_types=centroid_tolerance_types,powers=powers)\n",
    "mod.to_csv('C:\\\\Users\\\\jonah\\\\projects\\\\specsim_res\\\\noise_second_0.5_200.csv')\n",
    "del(matches)\n",
    "del(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keep_indices(noise_threshes, centroid_tolerance_vals, powers, spec_features, spec_change_features, sim_methods, any_=False, nonspecs=False, init_spec=False):\n",
    "\n",
    "    if nonspecs:\n",
    "        keep_indices= list(range(14))\n",
    "    else:\n",
    "        keep_indices=list()\n",
    "\n",
    "    if init_spec:\n",
    "        keep_indices+=list(range(14,24))\n",
    "\n",
    "    ind=24\n",
    "    for i in noise_threshes:\n",
    "        for j in centroid_tolerance_vals:\n",
    "            for k in powers:\n",
    "                \n",
    "                for l in spec_features:\n",
    "                    if any_:\n",
    "                        if True in [i,j,k,l]:\n",
    "                            keep_indices.append(ind)\n",
    "                    else:\n",
    "                        if i==j==k==l==True:\n",
    "                            keep_indices.append(ind)\n",
    "                    ind+=1\n",
    "\n",
    "                for l in spec_change_features:\n",
    "                    if any_:\n",
    "                        if True in [i,j,k,l]:\n",
    "                            keep_indices.append(ind)\n",
    "                    else:\n",
    "                        if i==j==k==l==True:\n",
    "                            keep_indices.append(ind)\n",
    "                    ind+=1\n",
    "\n",
    "\n",
    "                for l in sim_methods:\n",
    "                    \n",
    "                    if any_:\n",
    "                        if True in [i,j,k,l]:\n",
    "                            keep_indices.append(ind)\n",
    "                    else:\n",
    "                        if i==j==k==l==True:\n",
    "                            keep_indices.append(ind)\n",
    "                    ind+=1\n",
    "\n",
    "    return keep_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cff19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns[14:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa084c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_threshes=[0.01,0.1,0.2]\n",
    "centroid_tolerance_vals = [0.05,1]\n",
    "centroid_tolerance_types=['da','ppm']\n",
    "powers=[0.25,1,3,'ent']\n",
    "sim_methods = ['lorentzian','max_entropy','squared_chord','lorentzian_jonah','rbf','ave_bhattacharya_2','max_bhattacharya_2']\n",
    "\n",
    "\n",
    "noise_threshes=[True,True,True]\n",
    "centroid_tolerance_values=[True,False]\n",
    "powers=[True,True,True,True]\n",
    "spec_features=[True,True, False,False,False,False,False,False]#8\n",
    "spec_change_features = [False for i in range(8)]#8\n",
    "sim_methods=[True,False,False,False,False,False]#7\n",
    "\n",
    "#cols['nonspec_only']=generate_keep_indices(noise_threshes, centroid_tolerance_values, powers, spec_features, spec_change_features, sim_methods, any_=True, nonspecs=True)\n",
    "cols2['first_2_spec_lor_only']=generate_keep_indices(noise_threshes, centroid_tolerance_values, powers, spec_features, spec_change_features, sim_methods, any_=False, nonspecs=False, init_spec=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a20e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/specsim_res/col_dict.pickle', 'rb') as handle:\n",
    "    cols = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_auc_test = [\n",
    "    ('all',cols['all'],hgbc()),\n",
    "    ('all_but_nonspec',cols['all_but_nonspec'],hgbc()),\n",
    "    ('nonspec_only',cols['nonspec_only'],hgbc()),\n",
    "    ('first_2_spec_lor_only',cols2['first_2_spec_lor_only'],hgbc()),\n",
    "    ('first_2_spec',cols2['first_2_spec'],hgbc())\n",
    "]\n",
    "\n",
    "for i in cols_auc_test:\n",
    "    i[2].fit(pd.concat((train.iloc[:,i[1]],val.iloc[:,i[1]])), pd.concat((train.iloc[:,-1:],val.iloc[:,-1:])))\n",
    "\n",
    "    print(f'trained: {i[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2974f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=list()\n",
    "\n",
    "for i in cols['all_sims']:\n",
    "\n",
    "    metrics.append((test.columns[i], i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b712e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tests)\n",
    "\n",
    "aucs_res = tests.run_metrics_models_auc(metrics, cols_auc_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ddf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_res = {k: v for k, v in sorted(aucs_res.items(), key=lambda item: -1*item[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400de306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "a=np.random.beta(a=1,b=5,size=10000)*200\n",
    "plt.hist(a, weights=np.ones(len(a)) / len(a), bins=40)\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.title('Distribution Over Peak Heights When Y=100')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaaf077",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0efa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "mods = list()\n",
    "\n",
    "for i in res_dict:\n",
    "\n",
    "    mods=mods+[j[0] for j in res_dict[i]]\n",
    "\n",
    "for i in res_dict2:\n",
    "\n",
    "    mods=mods+[j[0] for j in res_dict2[i]]\n",
    "\n",
    "Counter(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd53b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Volumes/Untitled/specsim_res/noise_first_1_100.csv').iloc[:,1:]\n",
    "test = pd.read_csv('/Volumes/Untitled/specsim_res/noise_second_1_100.csv').iloc[:,1:]\n",
    "\n",
    "print(len(train))\n",
    "train.dropna(how='any', inplace=True)\n",
    "print(len(train))\n",
    "\n",
    "print(len(test))\n",
    "test.dropna(how='any', inplace=True)\n",
    "print(len(test))\n",
    "\n",
    "val=test.iloc[:int(2e5)]\n",
    "test=test.iloc[int(2e5):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[:10,cols['nonspec_only']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e80542",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/specsim_res/col_dict.pickle', 'rb') as handle:\n",
    "    cols = pickle.load(handle)\n",
    "\n",
    "cols['random_half']=list(np.random.choice(576,size=int(576/2),replace=False))\n",
    "cols['random_quarter']=list(np.random.choice(576,size=int(576/4),replace=False))\n",
    "cols['random_eighth']=list(np.random.choice(576,size=int(576/8),replace=False))\n",
    "cols['random_tenth']=list(np.random.choice(576,size=int(576/10),replace=False))\n",
    "cols['all']=list(range(576))\n",
    "\n",
    "print(len(cols))\n",
    "for i in cols:\n",
    "    print(f'{i} {len(cols[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e0aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def zero_one_loss(preds, true):\n",
    "    \n",
    "    preds=np.array(preds).squeeze()\n",
    "    true=np.array(true).squeeze()\n",
    "    \n",
    "    return sum(abs(true-preds))/len(true)\n",
    "\n",
    "def best_model_select(models, train, val, test):\n",
    "    \n",
    "    model_errs = np.zeros(len(models))\n",
    "    train['match']=train['match'].astype(int)\n",
    "    val['match']=val['match'].astype(int)\n",
    "    test['match']=test['match'].astype(int)\n",
    "\n",
    "    best_model = None\n",
    "    best_error=np.inf\n",
    "\n",
    "    i=0\n",
    "    for model in models:\n",
    "\n",
    "        clf = sklearn.base.clone(model)\n",
    "        clf.fit(train.iloc[:,:-1], train.iloc[:,-1])\n",
    "        val_error = zero_one_loss(clf.predict(val.iloc[:,:-1]),val.iloc[:,-1:].to_numpy())\n",
    "\n",
    "        if val_error < best_error:\n",
    "            best_model=copy.deepcopy(clf)\n",
    "            best_error = val_error\n",
    "\n",
    "        del(clf)\n",
    "        model_errs[i]=val_error\n",
    "        i+=1\n",
    "\n",
    "    return str(best_model), zero_one_loss(best_model.predict(test.iloc[:,:-1]),test.iloc[:,-1:].to_numpy()), model_errs\n",
    "\n",
    "def best_models_by_subset(cols, train_sizes, models, train, val, test):\n",
    "\n",
    "    res_dict=dict()\n",
    "    for key, value in cols.items():\n",
    "        res_dict[key]=list()\n",
    "\n",
    "        for size in train_sizes:\n",
    "    \n",
    "            res_dict[key].append(best_model_select(models, train.iloc[:size,value+[576]], val.iloc[:,value+[576]], test.iloc[:,value+[576]]))\n",
    "\n",
    "            print(f'finished {key} for {size}')\n",
    "\n",
    "    return res_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1653fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [\n",
    "        hgbc(),\n",
    "        hgbc(learning_rate=0.01),\n",
    "        hgbc(learning_rate=0.5),\n",
    "        hgbc(max_iter=200),\n",
    "        hgbc(learning_rate=0.01, max_iter=200),\n",
    "        hgbc(learning_rate=0.5, max_iter=200),\n",
    "        hgbc(min_samples_leaf=10),\n",
    "        hgbc(learning_rate=0.01,min_samples_leaf=10),\n",
    "        hgbc(learning_rate=0.5,min_samples_leaf=10),\n",
    "        hgbc(max_iter=200,min_samples_leaf=10),\n",
    "        hgbc(learning_rate=0.01, max_iter=200,min_samples_leaf=10),\n",
    "        hgbc(learning_rate=0.5, max_iter=200,min_samples_leaf=10),\n",
    "        ]\n",
    "\n",
    "#model, test_err, val_errs = best_model_select(models, train[:1000], val[:1000], test[:1000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes=[int(8e5)]\n",
    "res_dict2 = best_models_by_subset(cols2, train_sizes=train_sizes, models=models, train=train, val=val, test=test )\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/specsim_res/res_dict2.pickle', 'wb') as handle:\n",
    "    pickle.dump(res_dict2, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860df7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a737539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i in res_dict2:\n",
    "\n",
    "    if i in res_dict2:\n",
    "    #if 'all' in i or i=='nonspec_only':\n",
    "        test_errors = [j[1] for j in res_dict2[i]]\n",
    "        plt.scatter(train_sizes, test_errors, label=i)\n",
    "\n",
    "\n",
    "plt.title('Zero One Error by Proportion of Features Included')\n",
    "plt.xlabel('# of Training Points')\n",
    "plt.ylabel('Zero One Error')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede39df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spectral_similarity\n",
    "\n",
    "sims=list()\n",
    "for i in spectral_similarity.methods_range:\n",
    "    sims.append(i)\n",
    "    sims.append('max_'+i)\n",
    "    sims.append('min_'+i)\n",
    "    sims.append('ave_'+i)\n",
    "    \n",
    "mod_data = datasetBuilder.create_model_dataset(target, 10, sims, 10, nonspec_features=False, spec_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c84a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data=mod_data.iloc[:,1:]\n",
    "mod_data.columns=sims\n",
    "mod_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0df28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "scipy.stats.entropy([1 for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotAndOrderResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_res=pd.read_csv(\"C:\\\\Users\\\\jonah\\\\projects\\\\SpecSim\\\\allsim_res_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be656111",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAndOrderResults.add_evals_to_df(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAndOrderResults.order_criterion_from_df(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAndOrderResults.order_criterion_from_df(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool = spectral_similarity.multiple_similarity(b,a, ms2_da=0.05, methods=['max_lorentzian','reverse_lorentzian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d479e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool['reverse_lorentzian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6defbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool['reverse_entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = tools.match_peaks_in_spectra(a,b, ms2_da=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f3235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_distance._select_common_peaks(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61654785",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool = a>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea961519",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f5315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
