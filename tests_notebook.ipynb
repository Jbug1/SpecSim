{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f65d6f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-13T03:45:16.757600Z",
     "start_time": "2023-08-13T03:45:14.306478Z"
    }
   },
   "outputs": [],
   "source": [
    "import tests\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import datasetBuilder\n",
    "import tools\n",
    "import scipy\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as hgbc\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "import sklearn.base\n",
    "import pickle\n",
    "import copy\n",
    "import tests\n",
    "from sklearn.metrics import roc_auc_score as auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d7d8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = datasetBuilder.get_target_df('/Users/jonahpoczobutt/projects/raw_data/nist_out.MSP').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4442a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_to_df(aucs, trues):\n",
    "\n",
    "    mets =set()\n",
    "    for i in aucs.iloc[0]:\n",
    "        mets.add(i)\n",
    "\n",
    "    mets=list(mets)\n",
    "    outdict=dict()\n",
    "    outdict['metric']=list()\n",
    "    outdict['auc']=list()\n",
    "\n",
    "    for metric in mets:\n",
    "        temp = list()\n",
    "        for i in range(len(aucs)):\n",
    "\n",
    "            temp.append(aucs.iloc[i][metric])\n",
    "\n",
    "        try:\n",
    "            outdict['auc'].append(auc(trues, temp))\n",
    "            outdict['metric'].append(metric)\n",
    "        except:\n",
    "            print(f'error on {metric}')\n",
    "            \n",
    "\n",
    "    return pd.DataFrame(outdict)\n",
    "    \n",
    "\n",
    "def create_variable_comparisons(target, size, ppm_threshes, noise_threshes, centroid_threshes, centroid_types, powers, sim_methods, max_matches,outfolder):\n",
    "\n",
    "    for i in ppm_threshes:\n",
    "\n",
    "        matches = datasetBuilder.create_matches_df(target,i,max_matches,size)\n",
    "        filepath = f'{outfolder}/matches_{i}_ppm.csv'\n",
    "\n",
    "        for j in noise_threshes:\n",
    "            for k in range(len(centroid_threshes)):\n",
    "                for l in powers:\n",
    "\n",
    "                    cleaned = matches.apply(lambda x: datasetBuilder.clean_and_spec_features(x['query'],\n",
    "                                                                                             x['query_prec'],\n",
    "                                                                                             x['target'],\n",
    "                                                                                             x['target_prec'],\n",
    "                                                                                             noise_thresh=j,\n",
    "                                                                                             centroid_thresh = centroid_threshes[k],\n",
    "                                                                                             centroid_type=centroid_types[k],\n",
    "                                                                                             power=l\n",
    "                                                                                             ), \n",
    "                                                                                             axis=1,\n",
    "                                                                                             result_type='expand')\n",
    "                    \n",
    "                    \n",
    "                    cleaned=pd.DataFrame(cleaned)\n",
    "                    cleaned = cleaned.iloc[:,-2:]\n",
    "                    cleaned.columns = ['query','library']\n",
    "                                                                             \n",
    "                    aucs = tests.run_metrics_models_auc(sim_methods,[],cleaned, tol_thresh = centroid_threshes[k], tol_type=centroid_types[k])\n",
    "                    aucs = auc_to_df(aucs, list(matches.iloc[:,-1]))\n",
    "                    aucs['clean_specs'] =  f'{j}_{centroid_threshes[k]}_{centroid_types[k]}_{l}'\n",
    "                    print(f'{j}_{centroid_threshes[k]}_{centroid_types[k]}_{l}')\n",
    "                    aucs.to_csv(filepath, mode='a', header=False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0362de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tests)\n",
    "matches=datasetBuilder.create_matches_df(target,10,100,1e2)\n",
    "a = list(matches.columns)\n",
    "a[-2]='library'\n",
    "matches.columns=a\n",
    "\n",
    "sim = tests.run_metrics_models_auc(None, [], matches, 5, 'ppm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e965fd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_0.25\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_1\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_3\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_ent\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_3_ppm_None\n",
      "error on max_jensenshannon\n",
      "0.01_0.05_da_0.25\n",
      "error on max_jensenshannon\n",
      "0.01_0.05_da_1\n",
      "error on max_jensenshannon\n",
      "0.01_0.05_da_3\n",
      "error on max_jensenshannon\n",
      "0.01_0.05_da_ent\n",
      "error on max_jensenshannon\n",
      "0.01_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_3_ppm_None\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_0.25\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_1\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_3\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_ent\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_3_ppm_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_None\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_0.25\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_1\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_3\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_ent\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.01_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "0.01_3_ppm_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.05_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "0.05_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "0.05_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "0.05_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "0.05_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "0.05_3_ppm_None\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_0.25\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_1\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_3\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_ent\n",
      "error on correlation\n",
      "error on max_jensenshannon\n",
      "error on max_correlation\n",
      "0.1_0.05_da_None\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_0.25\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_1\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_3\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_ent\n",
      "error on max_jensenshannon\n",
      "0.1_3_ppm_None\n"
     ]
    }
   ],
   "source": [
    "noise_threshes=[0.01,0.05,0.1]\n",
    "centroid_tolerance_vals = [0.05,3]\n",
    "centroid_tolerance_types=['da','ppm']\n",
    "powers=[0.25,1,3,'ent',None]\n",
    "ppm_threshes = [3,5,10,15]\n",
    "\n",
    "create_variable_comparisons(target,\n",
    "                            size=5e4,\n",
    "                            ppm_threshes=ppm_threshes,\n",
    "                            noise_threshes=noise_threshes,\n",
    "                            centroid_threshes=centroid_tolerance_vals,\n",
    "                            centroid_types=centroid_tolerance_types,\n",
    "                            powers=powers,\n",
    "                            sim_methods=None,\n",
    "                            outfolder = '/Users/jonahpoczobutt/projects/specsim_res/individual_sims'\n",
    "                            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda901b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_bases = np.load('/Volumes/Untitled/raw_data/first_bases.npy')\n",
    "second_bases = np.load('/Volumes/Untitled/raw_data/second_bases.npy')\n",
    "\n",
    "first_target = target[np.isin(target['inchi_base'],first_bases)]\n",
    "#second_target = target[np.isin(target['inchi_base'],second_bases)]\n",
    "\n",
    "first_target.reset_index(inplace=True)\n",
    "#second_target.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84fa757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100007 rows created\n",
      "200005 rows created\n",
      "300026 rows created\n",
      "400023 rows created\n",
      "500033 rows created\n",
      "600002 rows created\n",
      "700078 rows created\n",
      "800090 rows created\n",
      "900038 rows created\n",
      "1000088 rows created\n"
     ]
    }
   ],
   "source": [
    "noise_threshes=[0.01,0.1,0.2]\n",
    "centroid_tolerance_vals = [0.05]\n",
    "centroid_tolerance_types=['da']\n",
    "powers=[0.25,1,3]\n",
    "sim_methods = ['lorentzian','squared_chord','lorentzian_jonah','entropy']\n",
    "\n",
    "matches = datasetBuilder.create_matches_df(first_target,10,100,1e6)\n",
    "#datasetBuilder.add_noises_to_matches(matches, scale_ratio=0.5, mult=200)\n",
    "#del(target)\n",
    "#del(first_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfdec348",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(target)\n",
    "del(first_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6809916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 10000 rows\n",
      "processed 110000 rows\n",
      "processed 210000 rows\n",
      "processed 310000 rows\n",
      "processed 410000 rows\n",
      "processed 510000 rows\n",
      "processed 610000 rows\n",
      "processed 710000 rows\n",
      "processed 810000 rows\n",
      "processed 910000 rows\n"
     ]
    }
   ],
   "source": [
    "reload(datasetBuilder)\n",
    "datasetBuilder.chunk_create_all_to_all('/Users/jonahpoczobutt/projects/specsim_res/all_to_all_1.csv',matches, sim_methods = sim_methods, noise_threshes_query=noise_threshes, centroid_tolerance_vals_query=centroid_tolerance_vals, centroid_tolerance_types_query=centroid_tolerance_types,powers_query=powers,noise_threshes_target=noise_threshes, centroid_tolerance_vals_target=centroid_tolerance_vals, centroid_tolerance_types_target=centroid_tolerance_types,powers_target=powers)\n",
    "del(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6464ac97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100032 rows created\n",
      "200005 rows created\n",
      "300011 rows created\n",
      "processed 10000 rows\n",
      "processed 110000 rows\n",
      "processed 210000 rows\n"
     ]
    }
   ],
   "source": [
    "second_target = target[np.isin(target['inchi_base'],second_bases)]\n",
    "second_target.reset_index(inplace=True)\n",
    "\n",
    "noise_threshes=[0.01,0.1,0.2]\n",
    "centroid_tolerance_vals = [0.05]\n",
    "centroid_tolerance_types=['da']\n",
    "powers=[0.25,1,3]\n",
    "sim_methods = ['lorentzian','squared_chord','lorentzian_jonah','entropy']\n",
    "\n",
    "matches = datasetBuilder.create_matches_df(second_target,10,100,3e5)\n",
    "\n",
    "datasetBuilder.chunk_create_all_to_all('/Users/jonahpoczobutt/projects/specsim_res/all_to_all_2.csv',matches, sim_methods = sim_methods, noise_threshes_query=noise_threshes, centroid_tolerance_vals_query=centroid_tolerance_vals, centroid_tolerance_types_query=centroid_tolerance_types,powers_query=powers,noise_threshes_target=noise_threshes, centroid_tolerance_vals_target=centroid_tolerance_vals, centroid_tolerance_types_target=centroid_tolerance_types,powers_target=powers)\n",
    "del(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a09b4a7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/Untitled/raw_data/nist_out.MSP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m target \u001b[39m=\u001b[39m datasetBuilder\u001b[39m.\u001b[39mget_target_df(\u001b[39m'\u001b[39m\u001b[39m/Volumes/Untitled/raw_data/nist_out.MSP\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m:]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#first_bases = np.load('/Volumes/Untitled/raw_data/first_bases.npy')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m#second_bases = np.load('/Volumes/Untitled/raw_data/second_bases.npy')\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#first_target = target[np.isin(target['inchi_base'],first_bases)]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m second_target \u001b[39m=\u001b[39m target[np\u001b[39m.\u001b[39misin(target[\u001b[39m'\u001b[39m\u001b[39minchi_base\u001b[39m\u001b[39m'\u001b[39m],second_bases)]\n",
      "File \u001b[0;32m~/projects/SpecSim/datasetBuilder.py:24\u001b[0m, in \u001b[0;36mget_target_df\u001b[0;34m(target_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_target_df\u001b[39m(\n\u001b[1;32m     20\u001b[0m     target_path,\n\u001b[1;32m     21\u001b[0m ):\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m     \u001b[39m# get whole dataframe from msp files\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     target_df \u001b[39m=\u001b[39m convert_msp_to_df_2(target_path)\n\u001b[1;32m     26\u001b[0m     \u001b[39m# get adduct subsets\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     target_df \u001b[39m=\u001b[39m get_adduct_subset(target_df)\n",
      "File \u001b[0;32m~/projects/SpecSim/datasetBuilder.py:269\u001b[0m, in \u001b[0;36mconvert_msp_to_df_2\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_msp_to_df_2\u001b[39m(filepath):\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filepath) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    270\u001b[0m         lines \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mreadlines()\n\u001b[1;32m    272\u001b[0m     names \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Volumes/Untitled/raw_data/nist_out.MSP'"
     ]
    }
   ],
   "source": [
    "target = datasetBuilder.get_target_df('/Volumes/Untitled/raw_data/nist_out.MSP').iloc[:,1:]\n",
    "\n",
    "#first_bases = np.load('/Volumes/Untitled/raw_data/first_bases.npy')\n",
    "#second_bases = np.load('/Volumes/Untitled/raw_data/second_bases.npy')\n",
    "\n",
    "#first_target = target[np.isin(target['inchi_base'],first_bases)]\n",
    "second_target = target[np.isin(target['inchi_base'],second_bases)]\n",
    "\n",
    "#first_target.reset_index(inplace=True)\n",
    "second_target.reset_index(inplace=True)\n",
    "\n",
    "matches = datasetBuilder.create_matches_df(second_target,10,100,1e6)\n",
    "datasetBuilder.add_noises_to_matches(matches, scale_ratio=0.5, mult=200)\n",
    "del(target)\n",
    "del(second_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92319d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 10000 rows\n",
      "processed 110000 rows\n",
      "processed 210000 rows\n",
      "processed 310000 rows\n",
      "processed 410000 rows\n",
      "processed 510000 rows\n",
      "processed 610000 rows\n",
      "processed 710000 rows\n",
      "processed 810000 rows\n",
      "processed 910000 rows\n"
     ]
    }
   ],
   "source": [
    "datasetBuilder.chunk_create_all_to_all('/Users/jonahpoczobutt/projects/specsim_res/all_to_all2_1_200.csv',matches, sim_methods = sim_methods, noise_threshes_query=noise_threshes, centroid_tolerance_vals_query=centroid_tolerance_vals, centroid_tolerance_types_query=centroid_tolerance_types,powers_query=powers,noise_threshes_target=noise_threshes, centroid_tolerance_vals_target=centroid_tolerance_vals, centroid_tolerance_types_target=centroid_tolerance_types,powers_target=powers)\n",
    "del(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6884435",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdel\u001b[39;00m(matches)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdel\u001b[39;00m(mod)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonahpoczobutt/projects/SpecSim/tests_notebook.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdel\u001b[39;00m (first_target)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "del(matches)\n",
    "del(mod)\n",
    "del (first_target)\n",
    "second_target = target[np.isin(target['inchi_base'],second_bases)]\n",
    "\n",
    "noise_threshes=[0.01,0.1,0.2]\n",
    "centroid_tolerance_vals = [0.05,1]\n",
    "centroid_tolerance_types=['da','ppm']\n",
    "powers=[0.25,1,3,'ent']\n",
    "sim_methods = ['lorentzian','max_entropy','squared_chord','lorentzian_jonah','rbf','ave_bhattacharya_2','max_bhattacharya_2']\n",
    "\n",
    "matches = datasetBuilder.create_matches_df(second_target,10,100,1e6)\n",
    "datasetBuilder.add_noises_to_matches(matches, scale_ratio=0.5, mult=200)\n",
    "print(f'match len predrop {len(matches)}')\n",
    "matches=matches.dropna(how='any')\n",
    "print(f'match len postdrop {len(matches)}')\n",
    "\n",
    "mod = datasetBuilder.create_model_dataset(matches, sim_methods = sim_methods, noise_threshes=noise_threshes, centroid_tolerance_vals=centroid_tolerance_vals, centroid_tolerance_types=centroid_tolerance_types,powers=powers)\n",
    "mod.to_csv('C:\\\\Users\\\\jonah\\\\projects\\\\specsim_res\\\\noise_second_0.5_200.csv')\n",
    "del(matches)\n",
    "del(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6dcbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_threshes=[0.01,0.1,0.2]\n",
    "centroid_tolerance_vals = [0.05]\n",
    "centroid_tolerance_types=['da']\n",
    "powers=[0.25,1,3]\n",
    "sim_methods = ['lorentzian','squared_chord','lorentzian_jonah','entropy']\n",
    "\n",
    "noise_threshes=[True, True, True]\n",
    "centroid_tolerance_vals = [True]\n",
    "centroid_tolerance_types=[True]\n",
    "powers=[True,True, True]\n",
    "sim_methods = [True, True, True, True]\n",
    "\n",
    "\n",
    "def generate_keep_indices_all_to_all(noise_threshes_query, \n",
    "                                     centroid_tolerance_vals_query,\n",
    "                                     powers_query, \n",
    "                                     noise_threshes_target, \n",
    "                                     centroid_tolerance_vals_target,\n",
    "                                     powers_target,\n",
    "                                     spec_features_query, \n",
    "                                     spec_features_target, \n",
    "                                     sim_methods, \n",
    "                                     any_=False, \n",
    "                                     nonspecs=False, \n",
    "                                     init_spec=False):\n",
    "    \n",
    "        if nonspecs:\n",
    "            keep_indices= list(range(14))\n",
    "\n",
    "        else:\n",
    "            keep_indices=list()\n",
    "\n",
    "        if init_spec:\n",
    "            keep_indices+=list(range(14,24))\n",
    "\n",
    "        ind=24\n",
    "        for i in noise_threshes_target:\n",
    "            for j in centroid_tolerance_vals_target:\n",
    "                for k in powers_target:\n",
    "                    \n",
    "                    for l in spec_features_target:\n",
    "                        if any_:\n",
    "                            if True in [i,j,k,l,]:\n",
    "                                keep_indices.append(ind)\n",
    "                        else:\n",
    "                            if i==j==k==l==True:\n",
    "                                keep_indices.append(ind)\n",
    "                        ind+=1\n",
    "                        \n",
    "\n",
    "        for i_ in noise_threshes_query:\n",
    "            for j_ in centroid_tolerance_vals_query:\n",
    "                for k_ in powers_query:\n",
    "\n",
    "                    for l in spec_features_query:\n",
    "                        if any_:\n",
    "                            if True in [l,i_,j_,k_]:\n",
    "                                keep_indices.append(ind)\n",
    "                        else:\n",
    "                            if l==i_==j_==k_==True:\n",
    "                                keep_indices.append(ind)\n",
    "                        \n",
    "                        ind+=1\n",
    "                        \n",
    "\n",
    "\n",
    "        for i in noise_threshes_target:\n",
    "            for j in centroid_tolerance_vals_target:\n",
    "                for k in powers_target:\n",
    "                    for i_ in noise_threshes_query:\n",
    "                        for j_ in centroid_tolerance_vals_query:\n",
    "                            for k_ in powers_query:\n",
    "\n",
    "                                for l in sim_methods:\n",
    "                                    \n",
    "                                    if any_:\n",
    "                                        if True in [i,j,k,l,i_,j_,k_]:\n",
    "                                            keep_indices.append(ind)\n",
    "                                    else:\n",
    "                                        if i==j==k==l==i_==j_==k_==True:\n",
    "                                            keep_indices.append(ind)\n",
    "                                    \n",
    "                                    ind+=1\n",
    "\n",
    "        return keep_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fc8a4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_features_query=[True for i in range(4)]#8\n",
    "spec_features_target=spec_features_query\n",
    "\n",
    "\n",
    "generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c267c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/jonahpoczobutt/projects/specsim_res/all_to_all_1.csv')\n",
    "test = pd.read_csv('/Users/jonahpoczobutt/projects/specsim_res/all_to_all_2.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87751d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_features_query=[True for i in range(4)]#8\n",
    "spec_features_target=spec_features_query\n",
    "\n",
    "noise_threshes=[True, True, True]\n",
    "powers=[True,True, True]\n",
    "noise_threshes_target=[True, True, True]\n",
    "powers_target=[True,True, True]\n",
    "sim_methods = [True, True, True, True]\n",
    "\n",
    "all_columns=dict()\n",
    "\n",
    "all_columns['all'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=True, \n",
    "                                nonspecs=True, \n",
    "                                init_spec=True)\n",
    "\n",
    "all_columns['all_but_nonspec'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=True)\n",
    "\n",
    "all_columns['all_but_nonspec_and_init'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[True, True, False]\n",
    "powers=[True,True, False]\n",
    "\n",
    "all_columns['23_query_setting'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[True, False, False]\n",
    "powers=[True,False, False]\n",
    "\n",
    "all_columns['13_query_setting'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[False, True, False]\n",
    "powers=[False,True, False]\n",
    "\n",
    "all_columns['13_query_setting_2'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[True, False, False]\n",
    "powers=[True,False, True]\n",
    "\n",
    "all_columns['1_noise_barbell_powers'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[True, False, True]\n",
    "powers=[False,True, False]\n",
    "\n",
    "all_columns['1_power_barbell_noise'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[True, True, True]\n",
    "powers=[True,True, True]\n",
    "sim_methods = [True, False,False,False]\n",
    "\n",
    "all_columns['all_loronly'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=True, \n",
    "                                nonspecs=True, \n",
    "                                init_spec=True)\n",
    "\n",
    "all_columns['all_but_nonspec_loronly'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=True)\n",
    "\n",
    "all_columns['all_but_nonspec_and_init_loronly'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "\n",
    "noise_threshes=[True, True, False]\n",
    "powers=[True,True, False]\n",
    "\n",
    "all_columns['23_query_setting_loronly'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[True, False, False]\n",
    "powers=[True,False, False]\n",
    "\n",
    "all_columns['13_query_setting_loronly'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[False, True, False]\n",
    "powers=[False,True, False]\n",
    "\n",
    "all_columns['13_query_setting_2_loronly'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[True, False, False]\n",
    "powers=[True,False, True]\n",
    "\n",
    "all_columns['1_noise_barbell_powers_loronly'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "noise_threshes=[True, False, True]\n",
    "powers=[False,True, False]\n",
    "sim_methods = [True, False,False,False]\n",
    "\n",
    "all_columns['1_power_barbell_noise_loronly'] = generate_keep_indices_all_to_all(noise_threshes, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers, \n",
    "                                noise_threshes_target, \n",
    "                                centroid_tolerance_vals,\n",
    "                                powers_target,\n",
    "                                spec_features_query=spec_features_query, \n",
    "                                spec_features_target=spec_features_target, \n",
    "                                sim_methods=sim_methods, \n",
    "                                any_=False, \n",
    "                                nonspecs=False, \n",
    "                                init_spec=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2474958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished all for None\n",
      "finished all_but_nonspec for None\n",
      "finished all_but_nonspec_and_init for None\n",
      "finished 23_query_setting for None\n",
      "finished 13_query_setting for None\n",
      "finished 13_query_setting_2 for None\n",
      "finished 1_noise_barbell_powers for None\n",
      "finished 1_power_barbell_noise for None\n",
      "finished all_loronly for None\n",
      "finished all_but_nonspec_loronly for None\n",
      "finished all_but_nonspec_and_init_loronly for None\n",
      "finished 23_query_setting_loronly for None\n",
      "finished 13_query_setting_loronly for None\n",
      "finished 13_query_setting_2_loronly for None\n",
      "finished 1_noise_barbell_powers_loronly for None\n",
      "finished 1_power_barbell_noise_loronly for None\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "        hgbc(),\n",
    "        hgbc(learning_rate=0.01),\n",
    "        hgbc(learning_rate=0.5),\n",
    "        hgbc(max_iter=200),\n",
    "        hgbc(learning_rate=0.01, max_iter=200),\n",
    "        hgbc(learning_rate=0.5, max_iter=200),\n",
    "        ]\n",
    "res_dict_a2a = best_models_by_subset(all_columns,train_sizes=[None],models=models, train=train, val=test[:50000], test=test[50000:],  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "776b3c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'all': [('HistGradientBoostingClassifier(learning_rate=0.5, max_iter=200)',\n",
       "   0.2252,\n",
       "   array([0.23556, 0.2438 , 0.24076, 0.22888, 0.23712, 0.22854]))],\n",
       " 'all_but_nonspec': [('HistGradientBoostingClassifier()',\n",
       "   0.28142,\n",
       "   array([0.29554, 0.31032, 0.30218, 0.29862, 0.30242, 0.29862]))],\n",
       " 'all_but_nonspec_and_init': [('HistGradientBoostingClassifier()',\n",
       "   0.313156,\n",
       "   array([0.3148 , 0.32762, 0.33644, 0.32078, 0.32252, 0.32662]))],\n",
       " '23_query_setting': [('HistGradientBoostingClassifier()',\n",
       "   0.311456,\n",
       "   array([0.31582, 0.32798, 0.33474, 0.31896, 0.32156, 0.3314 ]))],\n",
       " '13_query_setting': [('HistGradientBoostingClassifier()',\n",
       "   0.3134,\n",
       "   array([0.31684, 0.3274 , 0.32754, 0.31758, 0.32298, 0.31988]))],\n",
       " '13_query_setting_2': [('HistGradientBoostingClassifier(max_iter=200)',\n",
       "   0.325808,\n",
       "   array([0.33354, 0.33354, 0.33806, 0.32972, 0.33368, 0.33848]))],\n",
       " '1_noise_barbell_powers': [('HistGradientBoostingClassifier(max_iter=200)',\n",
       "   0.313312,\n",
       "   array([0.32008, 0.32626, 0.3267 , 0.31554, 0.3224 , 0.32928]))],\n",
       " '1_power_barbell_noise': [('HistGradientBoostingClassifier()',\n",
       "   0.31266,\n",
       "   array([0.31492, 0.32592, 0.3296 , 0.3151 , 0.31868, 0.3279 ]))],\n",
       " 'all_loronly': [('HistGradientBoostingClassifier(learning_rate=0.5, max_iter=200)',\n",
       "   0.222936,\n",
       "   array([0.2344 , 0.24568, 0.23048, 0.23108, 0.23852, 0.22988]))],\n",
       " 'all_but_nonspec_loronly': [('HistGradientBoostingClassifier(max_iter=200)',\n",
       "   0.280108,\n",
       "   array([0.30232, 0.31704, 0.2981 , 0.29698, 0.30722, 0.2999 ]))],\n",
       " 'all_but_nonspec_and_init_loronly': [('HistGradientBoostingClassifier()',\n",
       "   0.313604,\n",
       "   array([0.3214 , 0.3328 , 0.33876, 0.3252 , 0.32668, 0.33248]))],\n",
       " '23_query_setting_loronly': [('HistGradientBoostingClassifier(max_iter=200)',\n",
       "   0.315876,\n",
       "   array([0.3238 , 0.33368, 0.33452, 0.32234, 0.32824, 0.3301 ]))],\n",
       " '13_query_setting_loronly': [('HistGradientBoostingClassifier()',\n",
       "   0.3145,\n",
       "   array([0.32034, 0.332  , 0.33148, 0.32232, 0.32682, 0.33208]))],\n",
       " '13_query_setting_2_loronly': [('HistGradientBoostingClassifier()',\n",
       "   0.32796,\n",
       "   array([0.33584, 0.34026, 0.34228, 0.33668, 0.33854, 0.35214]))],\n",
       " '1_noise_barbell_powers_loronly': [('HistGradientBoostingClassifier(max_iter=200)',\n",
       "   0.313868,\n",
       "   array([0.32042, 0.33156, 0.3369 , 0.31904, 0.32724, 0.33162]))],\n",
       " '1_power_barbell_noise_loronly': [('HistGradientBoostingClassifier()',\n",
       "   0.31596,\n",
       "   array([0.32122, 0.33152, 0.33858, 0.32744, 0.32806, 0.33818]))]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict_a2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keep_indices(noise_threshes, centroid_tolerance_vals, powers, spec_features, spec_change_features, sim_methods, any_=False, nonspecs=False, init_spec=False):\n",
    "\n",
    "    if nonspecs:\n",
    "        keep_indices= list(range(14))\n",
    "    else:\n",
    "        keep_indices=list()\n",
    "\n",
    "    if init_spec:\n",
    "        keep_indices+=list(range(14,24))\n",
    "\n",
    "    ind=24\n",
    "    for i in noise_threshes:\n",
    "        for j in centroid_tolerance_vals:\n",
    "            for k in powers:\n",
    "                \n",
    "                for l in spec_features:\n",
    "                    if any_:\n",
    "                        if True in [i,j,k,l]:\n",
    "                            keep_indices.append(ind)\n",
    "                    else:\n",
    "                        if i==j==k==l==True:\n",
    "                            keep_indices.append(ind)\n",
    "                    ind+=1\n",
    "\n",
    "                for l in spec_change_features:\n",
    "                    if any_:\n",
    "                        if True in [i,j,k,l]:\n",
    "                            keep_indices.append(ind)\n",
    "                    else:\n",
    "                        if i==j==k==l==True:\n",
    "                            keep_indices.append(ind)\n",
    "                    ind+=1\n",
    "\n",
    "\n",
    "                for l in sim_methods:\n",
    "                    \n",
    "                    if any_:\n",
    "                        if True in [i,j,k,l]:\n",
    "                            keep_indices.append(ind)\n",
    "                    else:\n",
    "                        if i==j==k==l==True:\n",
    "                            keep_indices.append(ind)\n",
    "                    ind+=1\n",
    "\n",
    "    return keep_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cff19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns[14:24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa084c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_threshes=[0.01,0.1,0.2]\n",
    "centroid_tolerance_vals = [0.05,1]\n",
    "centroid_tolerance_types=['da','ppm']\n",
    "powers=[0.25,1,3,'ent']\n",
    "sim_methods = ['lorentzian','max_entropy','squared_chord','lorentzian_jonah','rbf','ave_bhattacharya_2','max_bhattacharya_2']\n",
    "\n",
    "\n",
    "noise_threshes=[True,True,True]\n",
    "centroid_tolerance_values=[True,False]\n",
    "powers=[True,True,True,True]\n",
    "spec_features=[True,True, False,False,False,False,False,False]#8\n",
    "spec_change_features = [False for i in range(8)]#8\n",
    "sim_methods=[True,False,False,False,False,False]#7\n",
    "\n",
    "#cols['nonspec_only']=generate_keep_indices(noise_threshes, centroid_tolerance_values, powers, spec_features, spec_change_features, sim_methods, any_=True, nonspecs=True)\n",
    "cols2['first_2_spec_lor_only']=generate_keep_indices(noise_threshes, centroid_tolerance_values, powers, spec_features, spec_change_features, sim_methods, any_=False, nonspecs=False, init_spec=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a20e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/specsim_res/col_dict.pickle', 'rb') as handle:\n",
    "    cols = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab4495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_auc_test = [\n",
    "    ('all',cols['all'],hgbc()),\n",
    "    ('all_but_nonspec',cols['all_but_nonspec'],hgbc()),\n",
    "    ('nonspec_only',cols['nonspec_only'],hgbc()),\n",
    "    ('first_2_spec_lor_only',cols2['first_2_spec_lor_only'],hgbc()),\n",
    "    ('first_2_spec',cols2['first_2_spec'],hgbc())\n",
    "]\n",
    "\n",
    "for i in cols_auc_test:\n",
    "    i[2].fit(pd.concat((train.iloc[:,i[1]],val.iloc[:,i[1]])), pd.concat((train.iloc[:,-1:],val.iloc[:,-1:])))\n",
    "\n",
    "    print(f'trained: {i[0]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2974f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=list()\n",
    "\n",
    "for i in cols['all_sims']:\n",
    "\n",
    "    metrics.append((test.columns[i], i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b712e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tests)\n",
    "\n",
    "aucs_res = tests.run_metrics_models_auc(metrics, cols_auc_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400de306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "a=np.random.beta(a=1,b=5,size=10000)*200\n",
    "plt.hist(a, weights=np.ones(len(a)) / len(a), bins=40)\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.title('Distribution Over Peak Heights When Y=100')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaaf077",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0efa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs_res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d6433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "mods = list()\n",
    "\n",
    "for i in res_dict:\n",
    "\n",
    "    mods=mods+[j[0] for j in res_dict[i]]\n",
    "\n",
    "for i in res_dict2:\n",
    "\n",
    "    mods=mods+[j[0] for j in res_dict2[i]]\n",
    "\n",
    "Counter(mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd53b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Volumes/Untitled/specsim_res/noise_first_1_100.csv').iloc[:,1:]\n",
    "test = pd.read_csv('/Volumes/Untitled/specsim_res/noise_second_1_100.csv').iloc[:,1:]\n",
    "\n",
    "print(len(train))\n",
    "train.dropna(how='any', inplace=True)\n",
    "print(len(train))\n",
    "\n",
    "print(len(test))\n",
    "test.dropna(how='any', inplace=True)\n",
    "print(len(test))\n",
    "\n",
    "val=test.iloc[:int(2e5)]\n",
    "test=test.iloc[int(2e5):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.iloc[:10,cols['nonspec_only']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e80542",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/specsim_res/col_dict.pickle', 'rb') as handle:\n",
    "    cols = pickle.load(handle)\n",
    "\n",
    "cols['random_half']=list(np.random.choice(576,size=int(576/2),replace=False))\n",
    "cols['random_quarter']=list(np.random.choice(576,size=int(576/4),replace=False))\n",
    "cols['random_eighth']=list(np.random.choice(576,size=int(576/8),replace=False))\n",
    "cols['random_tenth']=list(np.random.choice(576,size=int(576/10),replace=False))\n",
    "cols['all']=list(range(576))\n",
    "\n",
    "print(len(cols))\n",
    "for i in cols:\n",
    "    print(f'{i} {len(cols[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e0aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def zero_one_loss(preds, true):\n",
    "    \n",
    "    preds=np.array(preds).squeeze()\n",
    "    true=np.array(true).squeeze()\n",
    "    \n",
    "    return sum(abs(true-preds))/len(true)\n",
    "\n",
    "def best_model_select(models, train, val, test):\n",
    "    \n",
    "    model_errs = np.zeros(len(models))\n",
    "    train['match']=train['match'].astype(int)\n",
    "    val['match']=val['match'].astype(int)\n",
    "    test['match']=test['match'].astype(int)\n",
    "\n",
    "    best_model = None\n",
    "    best_error=np.inf\n",
    "\n",
    "    i=0\n",
    "    for model in models:\n",
    "\n",
    "        clf = sklearn.base.clone(model)\n",
    "        clf.fit(train.iloc[:,:-1], train.iloc[:,-1])\n",
    "        val_error = zero_one_loss(clf.predict(val.iloc[:,:-1]),val.iloc[:,-1:].to_numpy())\n",
    "\n",
    "        if val_error < best_error:\n",
    "            best_model=copy.deepcopy(clf)\n",
    "            best_error = val_error\n",
    "\n",
    "        del(clf)\n",
    "        model_errs[i]=val_error\n",
    "        i+=1\n",
    "\n",
    "    return str(best_model), zero_one_loss(best_model.predict(test.iloc[:,:-1]),test.iloc[:,-1:].to_numpy()), model_errs\n",
    "\n",
    "def best_models_by_subset(cols, train_sizes, models, train, val, test):\n",
    "\n",
    "    res_dict=dict()\n",
    "    for key, value in cols.items():\n",
    "        res_dict[key]=list()\n",
    "\n",
    "        for size in train_sizes:\n",
    "    \n",
    "            res_dict[key].append(best_model_select(models, train.iloc[:size,value+[-1]], val.iloc[:,value+[-1]], test.iloc[:,value+[-1]]))\n",
    "\n",
    "            print(f'finished {key} for {size}')\n",
    "\n",
    "    return res_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1653fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = [\n",
    "        hgbc(),\n",
    "        hgbc(learning_rate=0.01),\n",
    "        hgbc(learning_rate=0.5),\n",
    "        hgbc(max_iter=200),\n",
    "        hgbc(learning_rate=0.01, max_iter=200),\n",
    "        hgbc(learning_rate=0.5, max_iter=200),\n",
    "        hgbc(min_samples_leaf=10),\n",
    "        hgbc(learning_rate=0.01,min_samples_leaf=10),\n",
    "        hgbc(learning_rate=0.5,min_samples_leaf=10),\n",
    "        hgbc(max_iter=200,min_samples_leaf=10),\n",
    "        hgbc(learning_rate=0.01, max_iter=200,min_samples_leaf=10),\n",
    "        hgbc(learning_rate=0.5, max_iter=200,min_samples_leaf=10),\n",
    "        ]\n",
    "\n",
    "#model, test_err, val_errs = best_model_select(models, train[:1000], val[:1000], test[:1000]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5295f3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes=[int(8e5)]\n",
    "res_dict2 = best_models_by_subset(cols2, train_sizes=train_sizes, models=models, train=train, val=val, test=test )\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/jonahpoczobutt/projects/specsim_res/res_dict2.pickle', 'wb') as handle:\n",
    "    pickle.dump(res_dict2, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860df7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a737539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i in res_dict2:\n",
    "\n",
    "    if i in res_dict2:\n",
    "    #if 'all' in i or i=='nonspec_only':\n",
    "        test_errors = [j[1] for j in res_dict2[i]]\n",
    "        plt.scatter(train_sizes, test_errors, label=i)\n",
    "\n",
    "\n",
    "plt.title('Zero One Error by Proportion of Features Included')\n",
    "plt.xlabel('# of Training Points')\n",
    "plt.ylabel('Zero One Error')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede39df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spectral_similarity\n",
    "\n",
    "sims=list()\n",
    "for i in spectral_similarity.methods_range:\n",
    "    sims.append(i)\n",
    "    sims.append('max_'+i)\n",
    "    sims.append('min_'+i)\n",
    "    sims.append('ave_'+i)\n",
    "    \n",
    "mod_data = datasetBuilder.create_model_dataset(target, 10, sims, 10, nonspec_features=False, spec_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c84a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_data=mod_data.iloc[:,1:]\n",
    "mod_data.columns=sims\n",
    "mod_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0df28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "scipy.stats.entropy([1 for i in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea80c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotAndOrderResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_res=pd.read_csv(\"C:\\\\Users\\\\jonah\\\\projects\\\\SpecSim\\\\allsim_res_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be656111",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAndOrderResults.add_evals_to_df(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAndOrderResults.order_criterion_from_df(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7992f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotAndOrderResults.order_criterion_from_df(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5267a1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool = spectral_similarity.multiple_similarity(b,a, ms2_da=0.05, methods=['max_lorentzian','reverse_lorentzian'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d479e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool['reverse_lorentzian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6defbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool['reverse_entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21c4130",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = tools.match_peaks_in_spectra(a,b, ms2_da=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f3235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_distance._select_common_peaks(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61654785",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool = a>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea961519",
   "metadata": {},
   "outputs": [],
   "source": [
    "yool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4f5315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
